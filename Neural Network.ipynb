{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 218.1550 - mean_absolute_error: 13.4507 - val_loss: 33.1533 - val_mean_absolute_error: 4.3455\n",
      "Epoch 2/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.3369 - mean_absolute_error: 4.1294 - val_loss: 24.6433 - val_mean_absolute_error: 3.9197\n",
      "Epoch 3/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.8714 - mean_absolute_error: 3.7780 - val_loss: 23.2337 - val_mean_absolute_error: 3.8569\n",
      "Epoch 4/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.7980 - mean_absolute_error: 3.6139 - val_loss: 23.1546 - val_mean_absolute_error: 3.8905\n",
      "Epoch 5/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.5577 - mean_absolute_error: 3.6901 - val_loss: 22.6185 - val_mean_absolute_error: 3.8279\n",
      "Epoch 6/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.0369 - mean_absolute_error: 3.6121 - val_loss: 22.5030 - val_mean_absolute_error: 3.8157\n",
      "Epoch 7/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.5576 - mean_absolute_error: 3.7029 - val_loss: 22.8796 - val_mean_absolute_error: 3.8346\n",
      "Epoch 8/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.0458 - mean_absolute_error: 3.6351 - val_loss: 22.8275 - val_mean_absolute_error: 3.8277\n",
      "Epoch 9/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 20.6178 - mean_absolute_error: 3.5773 - val_loss: 22.6047 - val_mean_absolute_error: 3.8399\n",
      "Epoch 10/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.0973 - mean_absolute_error: 3.5864 - val_loss: 22.5014 - val_mean_absolute_error: 3.8317\n",
      "Epoch 11/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.2304 - mean_absolute_error: 3.4768 - val_loss: 22.5227 - val_mean_absolute_error: 3.8516\n",
      "Epoch 12/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8290 - mean_absolute_error: 3.5087 - val_loss: 22.4141 - val_mean_absolute_error: 3.8627\n",
      "Epoch 13/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.7179 - mean_absolute_error: 3.5410 - val_loss: 22.5977 - val_mean_absolute_error: 3.8826\n",
      "Epoch 14/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.8369 - mean_absolute_error: 3.6302 - val_loss: 22.5105 - val_mean_absolute_error: 3.8263\n",
      "Epoch 15/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8865 - mean_absolute_error: 3.4450 - val_loss: 22.2145 - val_mean_absolute_error: 3.8361\n",
      "Epoch 16/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2533 - mean_absolute_error: 3.5000 - val_loss: 22.3377 - val_mean_absolute_error: 3.8539\n",
      "Epoch 17/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.3982 - mean_absolute_error: 3.3972 - val_loss: 22.4235 - val_mean_absolute_error: 3.8526\n",
      "Epoch 18/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.5016 - mean_absolute_error: 3.4098 - val_loss: 22.6382 - val_mean_absolute_error: 3.8311\n",
      "Epoch 19/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7447 - mean_absolute_error: 3.4324 - val_loss: 22.3179 - val_mean_absolute_error: 3.8486\n",
      "Epoch 20/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.3827 - mean_absolute_error: 3.3921 - val_loss: 22.8649 - val_mean_absolute_error: 3.8413\n",
      "Epoch 21/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3624 - mean_absolute_error: 3.4657 - val_loss: 22.5579 - val_mean_absolute_error: 3.8857\n",
      "Epoch 22/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.5985 - mean_absolute_error: 3.4211 - val_loss: 22.3981 - val_mean_absolute_error: 3.8454\n",
      "Epoch 23/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0632 - mean_absolute_error: 3.4767 - val_loss: 22.5164 - val_mean_absolute_error: 3.8498\n",
      "Epoch 24/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.4583 - mean_absolute_error: 3.4727 - val_loss: 22.6687 - val_mean_absolute_error: 3.8614\n",
      "Epoch 25/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.9013 - mean_absolute_error: 3.3504 - val_loss: 22.9614 - val_mean_absolute_error: 3.8992\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.2412 - mean_absolute_error: 3.6967 \n",
      "Mean Absolute Error on the test set: 3.9150612354278564\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')  # Replace 'your_data.csv' with the actual file path\n",
    "\n",
    "# Separate features and target variable\n",
    "features = data.drop('count', axis=1)\n",
    "target = data['count']\n",
    "\n",
    "# Handle categorical features\n",
    "# categorical_features = ['April', 'August', 'December', 'January', 'July', 'June',\n",
    "#                         'March', 'May', 'November', 'October', 'September',\n",
    "#                         'Friday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
    "#                         'Wednesday', 'Christmas Day', 'Christmas Eve', 'Columbus Day',\n",
    "#                         'Halloween', 'Independence Day', 'Labor Day', 'Martin Luther King Jr. Day',\n",
    "#                         'Memorial Day', \"New Year's Day\", \"New Year's Eve\",\n",
    "#                         \"Presidents' Day\", \"St. Patrick's Day\", 'Thanksgiving Day',\n",
    "#                         \"Valentine's Day\", \"Veterans Day\"]\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "# features = pd.get_dummies(features, columns=categorical_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Linear activation for regression tasks\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Absolute Error on the test set: {mae}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 207.7359 - mean_absolute_error: 12.7805 - val_loss: 33.3106 - val_mean_absolute_error: 4.3550\n",
      "Epoch 2/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.1535 - mean_absolute_error: 4.1150 - val_loss: 23.9988 - val_mean_absolute_error: 3.8994\n",
      "Epoch 3/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.9356 - mean_absolute_error: 3.8964 - val_loss: 22.6290 - val_mean_absolute_error: 3.8456\n",
      "Epoch 4/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.8450 - mean_absolute_error: 3.7060 - val_loss: 22.3746 - val_mean_absolute_error: 3.8303\n",
      "Epoch 5/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.1286 - mean_absolute_error: 3.6933 - val_loss: 22.2406 - val_mean_absolute_error: 3.7986\n",
      "Epoch 6/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.1866 - mean_absolute_error: 3.5563 - val_loss: 22.2703 - val_mean_absolute_error: 3.8398\n",
      "Epoch 7/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.1142 - mean_absolute_error: 3.6225 - val_loss: 22.3019 - val_mean_absolute_error: 3.8319\n",
      "Epoch 8/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.6388 - mean_absolute_error: 3.6363 - val_loss: 22.0827 - val_mean_absolute_error: 3.8145\n",
      "Epoch 9/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.3276 - mean_absolute_error: 3.6914 - val_loss: 22.7139 - val_mean_absolute_error: 3.8260\n",
      "Epoch 10/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.3304 - mean_absolute_error: 3.5956 - val_loss: 22.4154 - val_mean_absolute_error: 3.8395\n",
      "Epoch 11/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8565 - mean_absolute_error: 3.5579 - val_loss: 22.2759 - val_mean_absolute_error: 3.8351\n",
      "Epoch 12/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.5688 - mean_absolute_error: 3.5798 - val_loss: 22.6015 - val_mean_absolute_error: 3.8463\n",
      "Epoch 13/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.2550 - mean_absolute_error: 3.4548 - val_loss: 22.6518 - val_mean_absolute_error: 3.8715\n",
      "Epoch 14/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.6582 - mean_absolute_error: 3.4667 - val_loss: 22.8749 - val_mean_absolute_error: 3.8895\n",
      "Epoch 15/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.3728 - mean_absolute_error: 3.5169 - val_loss: 22.9050 - val_mean_absolute_error: 3.9205\n",
      "Epoch 16/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2904 - mean_absolute_error: 3.5122 - val_loss: 22.7834 - val_mean_absolute_error: 3.9074\n",
      "Epoch 17/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7571 - mean_absolute_error: 3.4248 - val_loss: 22.8536 - val_mean_absolute_error: 3.8656\n",
      "Epoch 18/100\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 19.1700 - mean_absolute_error: 3.4794 - val_loss: 22.5898 - val_mean_absolute_error: 3.8794\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.9322 - mean_absolute_error: 3.7606 \n",
      "Mean Absolute Error on the test set: 3.9377918243408203\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')  # Replace 'your_data.csv' with the actual file path\n",
    "\n",
    "# Separate features and target variable\n",
    "features = data.drop('count', axis=1)\n",
    "target = data['count']\n",
    "\n",
    "# Handle categorical features\n",
    "# categorical_features = ['April', 'August', 'December', 'January', 'July', 'June',\n",
    "#                         'March', 'May', 'November', 'October', 'September',\n",
    "#                         'Friday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
    "#                         'Wednesday', 'Christmas Day', 'Christmas Eve', 'Columbus Day',\n",
    "#                         'Halloween', 'Independence Day', 'Labor Day', 'Martin Luther King Jr. Day',\n",
    "#                         'Memorial Day', \"New Year's Day\", \"New Year's Eve\",\n",
    "#                         \"Presidents' Day\", \"St. Patrick's Day\", 'Thanksgiving Day',\n",
    "#                         \"Valentine's Day\", \"Veterans Day\"]\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "# features = pd.get_dummies(features, columns=categorical_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Linear activation for regression tasks\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Absolute Error on the test set: {mae}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Public\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 142.8482 - mean_absolute_error: 9.5591 - val_loss: 31.9560 - val_mean_absolute_error: 4.3160\n",
      "Epoch 2/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.5637 - mean_absolute_error: 4.1619 - val_loss: 24.1186 - val_mean_absolute_error: 3.9300\n",
      "Epoch 3/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23.1375 - mean_absolute_error: 3.8151 - val_loss: 22.9376 - val_mean_absolute_error: 3.8753\n",
      "Epoch 4/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.8995 - mean_absolute_error: 3.7283 - val_loss: 23.1101 - val_mean_absolute_error: 3.8434\n",
      "Epoch 5/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 20.6991 - mean_absolute_error: 3.6313 - val_loss: 22.7302 - val_mean_absolute_error: 3.8698\n",
      "Epoch 6/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.0748 - mean_absolute_error: 3.5680 - val_loss: 22.4345 - val_mean_absolute_error: 3.8519\n",
      "Epoch 7/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.0868 - mean_absolute_error: 3.6380 - val_loss: 22.4347 - val_mean_absolute_error: 3.8325\n",
      "Epoch 8/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.5756 - mean_absolute_error: 3.5921 - val_loss: 22.7087 - val_mean_absolute_error: 3.8974\n",
      "Epoch 9/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.0280 - mean_absolute_error: 3.6365 - val_loss: 22.4063 - val_mean_absolute_error: 3.8334\n",
      "Epoch 10/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.1407 - mean_absolute_error: 3.5725 - val_loss: 22.6086 - val_mean_absolute_error: 3.8359\n",
      "Epoch 11/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.2589 - mean_absolute_error: 3.6057 - val_loss: 23.0517 - val_mean_absolute_error: 3.9527\n",
      "Epoch 12/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.3751 - mean_absolute_error: 3.5055 - val_loss: 23.8279 - val_mean_absolute_error: 4.0220\n",
      "Epoch 13/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3563 - mean_absolute_error: 3.5095 - val_loss: 23.2799 - val_mean_absolute_error: 3.8959\n",
      "Epoch 14/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4984 - mean_absolute_error: 3.5280 - val_loss: 23.0703 - val_mean_absolute_error: 3.8773\n",
      "Epoch 15/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.9083 - mean_absolute_error: 3.4417 - val_loss: 23.0841 - val_mean_absolute_error: 3.8794\n",
      "Epoch 16/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.2227 - mean_absolute_error: 3.3892 - val_loss: 24.6945 - val_mean_absolute_error: 3.9588\n",
      "Epoch 17/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.6778 - mean_absolute_error: 3.5134 - val_loss: 22.5985 - val_mean_absolute_error: 3.8888\n",
      "Epoch 18/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.3637 - mean_absolute_error: 3.3951 - val_loss: 23.1256 - val_mean_absolute_error: 3.9711\n",
      "Epoch 19/30\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.2853 - mean_absolute_error: 3.4221 - val_loss: 23.2226 - val_mean_absolute_error: 3.8967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.4786 - mean_absolute_error: 3.7164\n",
      "Mean Absolute Error on the test set: 3.907010316848755\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')  # Replace 'your_data.csv' with the actual file path\n",
    "\n",
    "# Separate features and target variable\n",
    "features = data.drop('count', axis=1)\n",
    "target = data['count']\n",
    "\n",
    "# Handle categorical features\n",
    "# categorical_features = ['April', 'August', 'December', 'January', 'July', 'June',\n",
    "#                         'March', 'May', 'November', 'October', 'September',\n",
    "#                         'Friday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
    "#                         'Wednesday', 'Christmas Day', 'Christmas Eve', 'Columbus Day',\n",
    "#                         'Halloween', 'Independence Day', 'Labor Day', 'Martin Luther King Jr. Day',\n",
    "#                         'Memorial Day', \"New Year's Day\", \"New Year's Eve\",\n",
    "#                         \"Presidents' Day\", \"St. Patrick's Day\", 'Thanksgiving Day',\n",
    "#                         \"Valentine's Day\", \"Veterans Day\"]\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "# features = pd.get_dummies(features, columns=categorical_features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Linear activation for regression tasks\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Absolute Error on the test set: {mae}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
